layout: post
title: JDP Core Data
---

如果当前你的数据分析团队陷入了如下的困惑：

- Hadoop生态圈复杂的技术栈
- 超高的学习成本与投入收效甚微
- 是否有一栈式方案，简单易上手
- 超大数据集处理，效率低下
- 海量数据流动，处理维护成本高昂
- 多平台数据融合，运维开发成本高

那么，恭喜你，JDP流分析平台，是非常适合你的。

JDP流分析平台是一套高性能实时数据处理解决方案，底层构建在分布式数据库，分布式数据处理引擎。

![JDP-Core-Data](http://www.fusionlab.cn/zh-cn/page/img/JDP-Core-Data.png)

我们的接入流程是：

#### 1. 数据评估

如果你想直接把自己的业务接入JDP平台，那么需要首先评估业务的数据量，建立JDP集群。主要包括 `数据量级` ， `数据增量`及`响应延迟`。

业务 | 增量  | 总量
--- | ---   | ---
A   | 10T   | 50T
B   | 1T    | 10T
C   | 3T    | 100T
D   | 5T    | 500T

无副本：

> 集群规模N=((总数据量+总增量)+0.2*(总数据量+总增量))/48T
> 
> N = 18 node

2副本：

> 集群规模N=(((总数据量+总增量)+0.2*(总数据量+总增量)))*2/48T
> 
> N = 33 node

3副本：

> 集群规模N=(((总数据量+总增量)+0.2*(总数据量+总增量)))*3/48T
> 
> N = 50 node

#### 2. 分析场景

业务  | 响应  | 事物
---  | ---   | ---
A    | 秒级  | OLTP
B    | 分钟级 | OLAP
C    | 毫秒级 | OLAP
D    | 小时级 | OLAP

目前JDP流分析平台，主要场景是高性能OLAP场景，未来考虑HTAP混合型场景，同事支持OLAP & OLTP的分布式数据库产品。

#### 2. 业务迁移

[1] 历史库可直接同步通过remote表实现，TB级高效率传输。

[2] MySQL数据库binlog，实时同步，支持Change Data Capture (CDC)

[3] Kafka Topic海量实时数据接入

[4] 标准化数据协议，分布式多节点数据加载

[5] 实时数据可视化系统，支持主流数据库

[6] 简单易用的的数据融合引擎，实现数据秒级转化

